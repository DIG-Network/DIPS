# DIP-0003: Proof of Unique Storage

## Abstract

The DIG Network's success depends on its ability to ensure that nodes genuinely contribute storage resources rather than simply proxying or sharing data. This proposal introduces "Proof of Unique Storage," a comprehensive mechanism that combines validator discovery, Chia wallet key verification, and asymmetric verified delay functions to guarantee that each rewarded node maintains a truly unique copy of stored data. By requiring nodes to perform computationally intensive but easily verifiable transformations on their stored data, we can prevent both proxy attacks and shared storage exploits while maintaining the network's efficiency and scalability.

## Understanding the Challenge

Today's DIG Network faces two significant vulnerabilities that could undermine its incentive structure. The first is proxy attacks, where malicious actors place themselves between legitimate mirrors and users, intercepting requests and claiming rewards without actually storing any data. The second, more subtle vulnerability is the shared storage exploit, where operators maintain a single copy of data but serve it through multiple endpoints, effectively claiming multiple rewards for a single storage contribution.

These vulnerabilities arise from a fundamental limitation: while we can verify that served content matches what's expected, we cannot easily prove that each node maintains its own unique copy. This limitation could lead to a tragedy of the commons where the network appears to have more storage capacity than it actually does, potentially compromising its resilience and decentralization.

To meet these challenges the DIG Network uses two proofs:

The first proof, called Proof of Key Location, verifies the authenticity of where data is being served from. Think of this like checking both a server's ID badge (its cryptographic key) and its physical location (IP address and port) at the same time. When a validator requests data from a node, this proof confirms that the response is genuinely coming from the claimed location and is signed by the correct cryptographic key. This prevents nodes from playing "pass the data" games where they might try to serve content from unauthorized locations.

The second proof, called Proof of Unique Content, ensures that each node maintains its own distinct copy of the data rather than sharing copies behind the scenes. This works through a special time-intensive transformation process that each node must perform on its data. The transformation depends on both the node's private key and the data itself, making it impossible for nodes to share transformed copies. When challenged, nodes must quickly produce their uniquely transformed data – something they can only do if they've actually performed and stored their own transformation.
Together, these proofs create a robust verification system. The Proof of Key and Location ensures data is being served from legitimate, authorized sources, while the Proof of Unique Content guarantees that each node is maintaining its own separate copy rather than just accessing shared storage. This combination helps maintain true redundancy in the network, as each copy of the data is provably distinct and properly bound to its hosting node.

# Proof 1 - Proof of Key Location

When a DIG Node wishes to mirror content, it creates a server coin. This coin's memo field contains all the information needed to verify the node's identity and capabilities:

```typescript
interface ServerCoinMemo {
    host: string;              // Mirror's network location
    walletPublicKey: string;   // Node's wallet public key
    epoch: number;             // Current network epoch
    signature: string;         // Signature binding the public key to this host and epoch
}
```

### Understanding Key Registration

The key registration process creates an unforgeable binding between a DIG Node's host address and its wallet public key. This binding is established through a cryptographic signature that combines:

1. The node's wallet public key
2. The host address where the node operates
3. The current network epoch number
4. A protocol-specific prefix to prevent signature reuse

The signature proves two critical things:
- The node controls the private key corresponding to the registered public key
- The node is authorized to operate at the specified host address

Now that we have cryptographic proof that the location and the public key are bound together, when the validator requests data from the DIG Node, it can provide a nonce that the DIG Node can sign proving that the response is from the right DIG Node.

# Proof 2 - Proof of Unique Storage

## Introduction

In decentralized storage networks, how can we be certain that multiple nodes are truly storing separate copies of data? This seemingly simple question touches on a fundamental challenge in distributed systems. When a network claims to have five copies of critical data stored across different nodes, we need to be absolutely certain those are five genuine, independent copies – not one copy being shared behind the scenes.

### The Shared Storage Exploit

Consider what happens in traditional storage networks. When we ask a node "Do you have this data?", they only need to prove they can retrieve it. This creates a dangerous vulnerability: multiple nodes could secretly share a single copy of the data while claiming separate storage. We call this the "shared storage exploit."

To understand why this matters, imagine a network that believes it has five redundant copies of important data, but in reality, all five nodes are accessing the same physical storage. If that single storage point fails, all redundancy is lost instantly – despite the network believing it had robust backup copies.

## Core Innovation: Triple Binding for True Redundancy

Our solution introduces a novel approach that binds three critical elements together:
1. The data itself
2. The node's cryptographic identity (its private key)
3. The node's network location (its IP address and port)

This binding is enforced through a time-intensive transformation that:
1. Cannot be shortcut or parallelized
2. Creates provably unique copies for each node
3. Can be quickly verified by others
4. Must be computed separately for each claimed copy
5. Transformation can be quickly reverse
6. Can verify the transformation without having to perform the transformation again

## System Architecture

### Standardized Time Investment

Rather than splitting files based on fixed chunk sizes, we normalize the processing time by splitting all files into a fixed number of chunks, regardless of file size. This provides several key benefits:

```typescript
interface ChunkingConfig {
    // Always split files into this many chunks
    standardChunkCount: number;  // e.g., 60 chunks
    // Target total processing time
    targetTotalTime: number;     // e.g., 60000ms (1 minute)
}

function calculateChunkBoundaries(
    fileSize: number,
    config: ChunkingConfig
): ChunkDefinition[] {
    const chunkSize = Math.ceil(fileSize / config.standardChunkCount);
    const chunks: ChunkDefinition[] = [];
    
    for (let i = 0; i < config.standardChunkCount; i++) {
        chunks.push({
            startOffset: i * chunkSize,
            length: Math.min(chunkSize, fileSize - (i * chunkSize)),
            index: i
        });
    }
    
    return chunks;
}
```

This approach ensures:
1. Every file takes about one minute to process, whether it's 1MB or 1GB
2. The time investment is meaningful but practical
3. The system's behavior is predictable and uniform

### Binding to Server Identity

Each chunk is cryptographically bound to both the node's private key and its network location:

```typescript
interface ServerIdentity {
    ipAddress: string;
    port: number;
    hostname?: string;
}

interface ChunkIdentity {
    server: ServerIdentity;
    publicKey: Buffer;
    privateKey: Buffer;
}

function initializeChunk(
    chunk: ChunkState, 
    identity: ChunkIdentity
): Buffer {
    // Create binding to server location
    const serverBinding = createServerBinding(
        identity.server,
        chunk.data
    );
    
    // Sign with private key to prove control of both
    // the key and server location
    const signedBinding = signWithPrivateKey(
        Buffer.concat([serverBinding, chunk.data]),
        identity.privateKey
    );

    // Combine everything into initial state
    return hash(
        Buffer.concat([
            chunk.data,
            serverBinding,
            signedBinding,
            chunk.previousChunkState
        ])
    );
}
```

This binding ensures that:
1. Each copy is unique to a specific node and location
2. Data cannot be served from unauthorized locations
3. Nodes cannot proxy or relocate data without detection

### The Verification Delay Function (VDF)

Once we have our initial state, we perform a time-intensive transformation that cannot be parallelized, using each chunk we construct a blockchain where each chunk is a block in the chain:

```typescript
/**
 * Represents the result of performing our Verified Delay Function.
 * This structure contains everything needed to prove the computation
 * was done correctly and allow for efficient verification.
 */
interface VDFResult {
    // The final state after all VDF iterations are complete.
    // This represents the transformed data that's unique to this node.
    finalState: Buffer;

    // Periodic snapshots of the VDF state taken during computation.
    // These allow verifiers to spot-check the computation without
    // redoing the entire thing.
    checkpoints: Buffer[];

    // Total number of iterations performed in the VDF.
    // Must meet or exceed minIterations requirement.
    iterations: number;

    // Cryptographic signature of the final state using the node's private key.
    // This proves the node with this private key actually did the computation.
    signature: Buffer;
}

/**
 * Performs the core Verified Delay Function computation on a chunk of data.
 * This function implements a chain of sequential hash operations that:
 * 1. Cannot be parallelized (each step depends on the previous step)
 * 2. Takes a predictable amount of time to compute
 * 3. Can be quickly verified using checkpoints
 * 
 * The VDF creates a unique transformation of the data that:
 * - Is bound to the node's private key
 * - Takes significant time to compute (~60 seconds)
 * - Can be verified in milliseconds
 * - Cannot be forged or computed in parallel
 * 
 * @param state - The current state of the chunk being processed
 * @param privateKey - The node's private key used to sign the result
 * @param minIterations - Minimum number of iterations required
 * @returns A VDFResult containing the final state and proof materials
 */
async function performVDF(
    state: ChunkState,
    privateKey: Buffer,
    minIterations: number
): Promise<VDFResult> {
    // Start with the initial state from the chunk
    let currentState = state.currentState;
    
    // Array to store periodic checkpoints for verification
    const checkpoints: Buffer[] = [];
    
    // Perform the required number of sequential iterations
    for (let i = 0; i < minIterations; i++) {
        // Each iteration has two steps:
        // 1. Hash the current state to get a new value
        const stateHash = hash(currentState);
        
        // 2. Mix the hash with the current state to produce the next state
        // This mixing ensures each state depends on all previous states
        // making it impossible to compute iterations in parallel
        currentState = mix(currentState, stateHash);
        
        // Store checkpoints periodically (every 10,000 iterations)
        // This allows verifiers to spot-check the computation without
        // redoing every step
        if (i % 10000 === 0) {
            checkpoints.push(currentState);
        }
    }
    
    // Once all iterations are complete, create the final result:
    return {
        // The transformed data after all iterations
        finalState: currentState,
        
        // The saved checkpoints for verification
        checkpoints,
        
        // Number of iterations performed
        iterations: minIterations,
        
        // Sign the final state with the node's private key
        // This cryptographically proves this specific node did the computation
        signature: signWithPrivateKey(privateKey, currentState)
    };
}
```

## Challenge and Verification System

### The Time-Based Security Model

The security of our system relies on a fundamental timing mismatch between proof generation and verification. When a node claims to store multiple copies, they face two requirements:

1. **Time Investment**: Each copy requires a full minute of sequential computation to create
2. **Storage Requirement**: Each transformed copy must be stored for fast verification

Let's see why this creates an unbeatable security model:

```typescript
interface ChallengeTiming {
    // Time allowed to respond to challenge
    challengeTimeout: number;  // 5000ms (5 seconds)
    
    // Time required for VDF computation
    vdfComputeTime: number;    // 60000ms (60 seconds)
    
    // Time to retrieve stored data
    storageReadTime: number;   // ~100ms
}

async function handleChallenge(
    challenge: StorageChallenge,
    storedData?: StoredCopy
): Promise<ChallengeResponse> {
    const startTime = Date.now();
    
    try {
        if (storedData) {
            // With stored data: Fast response
            const proof = await retrieveStoredProof(storedData, challenge);
            const responseTime = Date.now() - startTime;
            return {
                proof,
                responseTime,
                status: 'success'
            };
        } else {
            // Without stored data: Cannot meet timeout
            const originalData = await retrieveOriginalData();
            const proof = await computeVDFTransform(originalData);
            // Already exceeded 5-second timeout!
            return {
                status: 'timeout'
            };
        }
    } catch (error) {
        return { status: 'failed' };
    }
}
```

### Why Just-in-Time Computation Fails

Consider what happens when a challenge arrives:

1. **Challenge Arrives** (T = 0 seconds)
   - Node must prove they have chunk #37 from copy #3
   - 5-second timer starts

2. **Option A: Node Has Stored Data**
   - Read from storage (~100ms)
   - Verify integrity (~50ms)
   - Return proof
   - Total: ~150ms = Success!

3. **Option B: Node Tries to Recompute**
   - Read original data (~100ms)
   - Start VDF computation
   - At 5 seconds: Challenge times out
   - VDF needs 55 more seconds
   - Result: Failure

The timing mismatch makes cheating impossible:
- VDF computation (60s) takes 12x longer than the challenge timeout (5s)
- Can't parallelize (chunks are chained)
- Can't pre-compute (random challenges)
- Can't share proofs (bound to node's key and IP)

### Challenge Patterns

The system becomes even more secure through strategic challenge patterns:

```typescript
interface ChallengeStrategy {
    challengeFrequency: number;  // Every 10 minutes
    chunksPerChallenge: number;  // 3 random chunks
    minimumSuccessRate: number;  // 95% required
}

function issueChallenge(
    totalCopies: number,
    chunksPerCopy: number
): StorageChallenge {
    return {
        copyIndex: Math.floor(Math.random() * totalCopies),
        chunkIndex: Math.floor(Math.random() * chunksPerCopy),
        timeoutMs: 5000
    };
}
```

This creates a demanding verification environment:
1. Challenges come frequently and randomly
2. Multiple chunks checked per challenge
3. Quick response required
4. Success rate tracked over time

## Reward Claims and Verification

The system ties rewards to proven storage over time:

```typescript
interface RewardClaim {
    copyTimestamp: number;
    currentProof: StorageProof;
    challengeHistory: StorageChallenge[];
}

async function processRewardClaim(
    claim: RewardClaim
): Promise<boolean> {
    // Must prove current possession
    const hasValidStorage = await verifyStorageChallenge(
        {
            copyTimestamp: claim.copyTimestamp,
            chunkIndex: Math.floor(Math.random() * STANDARD_CHUNK_COUNT),
            timeoutMs: 5000
        },
        claim.currentProof
    );
    
    if (!hasValidStorage) {
        return false;
    }
    
    // Must show consistent challenge history
    return verifyChallengeHistory(claim.challengeHistory);
}
```

This ensures that:
1. Nodes must maintain continuous storage
2. Quick verification responses
3. Consistent challenge success
4. No gaps in storage history

## Fast Retrieval Mechanism

While our system requires a slow, time-intensive transformation for storing data, we need to serve that data quickly when users request it. This creates an interesting challenge: how can we make the forward transformation slow and sequential while keeping data retrieval fast? The solution lies in creating an asymmetric system where transformation is intentionally slow but reversal is nearly instant.

### The Theory of Asymmetric Reversal

When a node performs the VDF transformation on a chunk of data, it generates two key pieces:
1. The transformed (mutated) data
2. A reversal key that enables quick restoration of the original data

Think of this like a maze - finding your way through takes time, but if you've left behind a trail of breadcrumbs, following them back is quick and easy. Here's how we implement this concept:

```typescript
interface ReversalKey {
    // The main key used for fast reversal
    transformKey: Buffer;
    
    // A matrix or other mathematical structure that enables
    // quick inversion of the transformation
    reversalMatrix: Buffer;
    
    // Checksum of the original data for verification
    originalChecksum: Buffer;
    
    // Parameters used in the original transformation
    parameters: {
        iterations: number;
        seed: Buffer;
        nonce: Buffer;
    };
}

interface TransformedChunk {
    // The mutated data after VDF transformation
    mutatedData: Buffer;
    
    // Key for quick reversal
    reversalKey: ReversalKey;
    
    // Index of this chunk
    chunkIndex: number;
    
    // Proof that we did the transformation correctly
    proof: VDFProof;
}

async function generateReversalKey(
    originalChunk: Buffer,
    transformationState: TransformationState
): Promise<ReversalKey> {
    // During the VDF transformation, we collect information
    // that will help us reverse it quickly
    const transformKey = await computeTransformKey(
        originalChunk,
        transformationState
    );
    
    // Generate a mathematical structure (like a matrix)
    // that can quickly undo our transformation
    const reversalMatrix = await computeReversalMatrix(
        transformationState.iterations,
        transformationState.intermediateStates
    );
    
    // Store a checksum of the original data so we can
    // verify successful restoration
    const originalChecksum = hash(originalChunk);
    
    return {
        transformKey,
        reversalMatrix,
        originalChecksum,
        parameters: {
            iterations: transformationState.iterations,
            seed: transformationState.seed,
            nonce: transformationState.nonce
        }
    };
}

async function restoreOriginalData(
    mutatedData: Buffer,
    reversalKey: ReversalKey
): Promise<Buffer> {
    try {
        // Use our reversal matrix to quickly transform back
        const restored = await applyReversal(
            mutatedData,
            reversalKey.reversalMatrix,
            reversalKey.transformKey
        );
        
        // Verify we got back the original data
        const checksum = hash(restored);
        if (!checksum.equals(reversalKey.originalChecksum)) {
            throw new Error('Restoration verification failed');
        }
        
        return restored;
    } catch (error) {
        throw new Error(`Fast reversal failed: ${error.message}`);
    }
}

interface FastRetrievalService {
    // Returns original data for an HTTP request
    async serveChunk(
        request: ChunkRequest
    ): Promise<Buffer> {
        const transformedChunk = await this.storage.getChunk(
            request.chunkIndex
        );
        
        // Quick reversal using stored key
        const originalData = await restoreOriginalData(
            transformedChunk.mutatedData,
            transformedChunk.reversalKey
        );
        
        // Typical response time: 100-200ms
        return originalData;
    }
}
```

### Reversal Key Generation

The creation of effective reversal keys is crucial for fast retrieval. During the VDF transformation process, we:

1. Track Mathematical Properties: As we perform each iteration of the VDF, we record mathematical properties that will help us reverse the transformation quickly.

2. Build Reversal Structures: We construct specialized mathematical structures (like matrices or lookup tables) that enable fast reversal without needing to undo each VDF step individually.

3. Store Verification Data: We keep checksums and parameters that let us verify the reversal succeeded correctly.

### The Restoration Process

When a user requests data, the restoration process is nearly instant:

1. Retrieve Transformed Data (~50ms):
   - Load the mutated chunk from storage
   - Load the associated reversal key

2. Apply Fast Reversal (~50ms):
   - Use the reversal matrix to transform the data back
   - This is a single mathematical operation, not an iterative process

3. Verify Restoration (~10ms):
   - Check the result matches the stored checksum
   - Ensure the data integrity is maintained

Total time: ~100-200ms, well within normal HTTP response times.

### Validation Proofs: Verifying Key and Location Binding

When a validator challenges a node, it needs to verify two critical properties:
1. The transformed data was created using that node's private key
2. The data is being served from the correct network location

Let's explore how we create and verify proofs that demonstrate both properties simultaneously.

#### The Challenge-Response Protocol

First, let's look at how a challenge is structured and how nodes must respond:

```typescript
interface ChallengingValidator {
    // The validator's identity
    publicKey: Buffer;
    // Network location where validator operates
    networkLocation: ServerIdentity;
}

interface StorageChallenge {
    // Which chunk we're challenging
    chunkIndex: number;
    // Random nonce for this challenge
    challengeNonce: Buffer;
    // Timestamp of challenge
    timestamp: number;
    // Validator's signature on this challenge
    validatorSignature: Buffer;
}

interface ChallengeResponse {
    // The challenged chunk's transformed data
    mutatedData: Buffer;
    
    // Proof bundle showing key and location binding
    proof: {
        // Original binding to node's location
        serverBinding: Buffer;
        // Signature with node's private key
        keySignature: Buffer;
        // Current network info
        currentLocation: ServerIdentity;
    };
    
    // Response timing info
    respondedAt: number;
}
```

#### Creating Binding Proofs

When a node first transforms a chunk, it creates bindings to both its key and location:

```typescript
interface ChunkBindings {
    // Data bound to server location
    serverBinding: Buffer;
    // Data bound to private key
    keyBinding: Buffer;
    // Combined binding
    finalBinding: Buffer;
}

function createChunkBindings(
    chunk: Buffer,
    identity: NodeIdentity
): ChunkBindings {
    // First bind to server location
    const serverBinding = bindToLocation(
        chunk,
        identity.serverLocation
    );
    
    // Then bind that result to our private key
    const keyBinding = signWithPrivateKey(
        Buffer.concat([serverBinding, chunk]),
        identity.privateKey
    );
    
    // Combine both bindings
    const finalBinding = hash(
        Buffer.concat([
            serverBinding,
            keyBinding
        ])
    );
    
    return {
        serverBinding,
        keyBinding,
        finalBinding
    };
}

function bindToLocation(
    data: Buffer,
    location: ServerIdentity
): Buffer {
    // Create a binding that includes:
    // 1. Server's IP address
    // 2. Port number
    // 3. Optional hostname
    // 4. The data itself
    const locationInfo = Buffer.from(
        JSON.stringify({
            ip: location.ipAddress,
            port: location.port,
            hostname: location.hostname
        })
    );
    
    return hash(Buffer.concat([locationInfo, data]));
}
```

## Verifying Proofs

When validating a challenge response, we need to verify both bindings:

```typescript
interface ValidationContext {
    challenge: StorageChallenge;
    response: ChallengeResponse;
    expectedLocation: ServerIdentity;
    nodePublicKey: Buffer;
}

async function validateChallengeResponse(
    context: ValidationContext
): Promise<boolean> {
    // First verify timing
    if (!verifyTiming(context.challenge, context.response)) {
        return false;
    }
    
    // Verify the response comes from the correct location
    const locationValid = await verifyLocationBinding(
        context.response.mutatedData,
        context.response.proof.serverBinding,
        context.expectedLocation,
        context.response.proof.currentLocation
    );
    if (!locationValid) {
        return false;
    }
    
    // Verify the node's key was used
    const keyValid = verifyKeyBinding(
        context.response.mutatedData,
        context.response.proof.keySignature,
        context.nodePublicKey
    );
    if (!keyValid) {
        return false;
    }
    
    return true;
}

async function verifyLocationBinding(
    mutatedData: Buffer,
    claimedBinding: Buffer,
    expectedLocation: ServerIdentity,
    currentLocation: ServerIdentity
): Promise<boolean> {
    // First check the claimed location matches expected
    if (!locationsMatch(expectedLocation, currentLocation)) {
        return false;
    }
    
    // Recreate the binding and check it matches
    const computedBinding = bindToLocation(
        mutatedData,
        currentLocation
    );
    
    return computedBinding.equals(claimedBinding);
}

function verifyKeyBinding(
    mutatedData: Buffer,
    signature: Buffer,
    publicKey: Buffer
): boolean {
    // Verify the signature was made with the correct private key
    return verifySignature(
        publicKey,
        mutatedData,
        signature
    );
}
```

## Preventing Common Attacks

This dual verification system prevents several types of attacks:

### 1. Location Spoofing
If a node tries to serve data from a different location:
- The location binding won't match the expected location
- The validator can detect the mismatch

### 2. Key Sharing
If nodes try to share private keys:
- Each node's location is bound to its key
- Moving data to a new location or new key requires new bindings
- New bindings require the full VDF computation

### 3. Proxy Attacks
If a node tries to proxy requests to another location:
- The location binding verification will fail
- Response timing checks will likely fail due to proxy latency

### 4. Replay Attacks
If a node tries to replay old proofs:
- The challenge nonce ensures freshness
- Timestamp checking prevents old responses
- Location verification ensures current serving location

## Implementation in the Protocol

Here's how these proofs integrate into the full protocol:

```typescript
class ChunkValidator {
    constructor(
        private validatorIdentity: ChallengingValidator,
        private config: ValidationConfig
    ) {}
    
    async issueChallenge(
        node: NodeIdentity,
        chunk: ChunkInfo
    ): Promise<ChallengeResult> {
        // Create a challenge with nonce
        const challenge = this.createChallenge(
            chunk.index
        );
        
        // Request proof from node
        const response = await this.requestProof(
            node,
            challenge
        );
        
        // Validate the response
        const isValid = await validateChallengeResponse({
            challenge,
            response,
            expectedLocation: node.serverLocation,
            nodePublicKey: node.publicKey
        });
        
        // Record the result
        return {
            valid: isValid,
            timing: {
                challenged: challenge.timestamp,
                responded: response.respondedAt
            }
        };
    }
    
    private createChallenge(
        chunkIndex: number
    ): StorageChallenge {
        // Create a unique nonce
        const challengeNonce = randomBytes(32);
        
        // Current timestamp
        const timestamp = Date.now();
        
        // Sign the challenge
        const validatorSignature = signWithPrivateKey(
            Buffer.concat([
                Buffer.from(chunkIndex.toString()),
                challengeNonce,
                Buffer.from(timestamp.toString())
            ]),
            this.validatorIdentity.privateKey
        );
        
        return {
            chunkIndex,
            challengeNonce,
            timestamp,
            validatorSignature
        };
    }
}
```

## Verification Timing

The validation process is designed to be fast:
1. Location binding check: ~20ms
2. Key signature verification: ~10ms
3. Total verification time: ~50ms including network

This ensures validators can quickly verify proofs while still detecting any attempts to circumvent the location or key binding requirements.

The combination of cryptographic key binding and location verification creates a robust system where:
1. Data must be transformed using the node's private key
2. Transformed data must be served from the declared location 
3. Moving data between nodes requires a full retransformation
4. Proxy attempts are detected through timing and binding checks

This creates true data sovereignty - each copy is verifiably unique and tied to both a specific key and location.

### Storage Considerations

Storing reversal keys alongside transformed data requires some additional space, but the tradeoff is worth it:

```typescript
interface StorageRequirements {
    // Size of original chunk
    chunkSize: number;            // e.g., 1MB
    
    // Size of transformed data
    mutatedSize: number;          // ~1MB
    
    // Size of reversal key
    reversalKeySize: number;      // ~1KB
    
    // Size of verification data
    verificationSize: number;     // ~100B
}
```

For each 1MB chunk, we typically need:
- 1MB for the transformed data
- ~1KB for the reversal key
- ~100B for verification data

This roughly doubles our storage requirement, but enables:
- Fast data retrieval (~100ms)
- Efficient HTTP serving
- Quick challenge responses
- Data integrity verification

### Practical Implementation

In a production system, you'd typically implement the retrieval service like this:

```typescript
class ChunkRetrievalService {
    constructor(
        private storage: ChunkStorage,
        private metrics: MetricsService
    ) {}
    
    async serveHttpRequest(
        req: HttpRequest,
        res: HttpResponse
    ): Promise<void> {
        const startTime = Date.now();
        
        try {
            // Parse chunk request
            const chunkIndex = this.parseChunkRequest(req);
            
            // Get transformed data and reversal key
            const {
                mutatedData,
                reversalKey
            } = await this.storage.getChunk(chunkIndex);
            
            // Quick reversal
            const originalData = await restoreOriginalData(
                mutatedData,
                reversalKey
            );
            
            // Measure and track timing
            const duration = Date.now() - startTime;
            this.metrics.recordRetrieval(duration);
            
            // Send response
            res.send(originalData);
            
        } catch (error) {
            // Handle errors appropriately
            res.status(500).send(error.message);
        }
    }
}
```

This service provides:
1. Fast HTTP responses
2. Error handling
3. Performance monitoring
4. Data integrity checks

The end result is a system that's both secure and practical:
- Slow, intensive transformation when storing data
- Fast, efficient retrieval when serving data
- Strong integrity guarantees
- Production-ready performance